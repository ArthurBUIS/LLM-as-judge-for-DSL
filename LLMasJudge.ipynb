{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = '0' # i will give you the key later\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a text literal called greetings with value \"Hello\" and display greetings on the dashboard as a label.   ```envision\n",
      "greeting = \"Hello\" // define the text literal\n",
      "show label greeting // show the text literal as a label\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def readfile(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return file.read()\n",
    "docu =readfile(\"envision-brief.md\")    \n",
    "challenge = readfile(\"mychallenges/c\"+\"000\"+\".md\")\n",
    "\n",
    "# decompose challenge into question and prof_answer\n",
    "def decompose_challenge(challenge):\n",
    "    question,prof_answer=challenge.split(\"\\n\\n# ANSWER\\n\\n\")\n",
    "    return question, prof_answer\n",
    "question,prof_answer=decompose_challenge(challenge)\n",
    "print(question,prof_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```envision\n",
      "greetings = \"Hello\"\n",
      "show label \"\" a1b1 with greetings\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "coder_personality=\"You are a proficient coder in the Domain Specific Language called Envision. \\\n",
    "    Your task is to generate response to the given challenge. \\\n",
    "    Some challenges will ask you to generate Envision code,\\\n",
    "    others will ask you to explain given code or answer questions related to the Envision language. \\\n",
    "    Do not output any intermediate thinking, only give the final answer.\\\n",
    "    Here is the documentation of Envision:\\\n",
    "    ### Documentation\\n\" + docu\n",
    "coder_prompt=question\n",
    "\n",
    "coder_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": coder_personality},\n",
    "        {\"role\": \"user\", \"content\": coder_prompt}\n",
    "    ],\n",
    "    max_tokens=1000,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.2,\n",
    ")\n",
    "stud_sentence=coder_response.choices[0].message.content\n",
    "print(stud_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### QUESTION: define a text literal called greetings with value \"Hello\" and display greetings on the dashboard as a label.  \n",
      "### PROFESSOR ANSWER: ```envision\n",
      "greeting = \"Hello\" // define the text literal\n",
      "show label greeting // show the text literal as a label\n",
      "```\n",
      "### STUDENT ANSWER: ```envision\n",
      "greetings = \"Hello\"\n",
      "show label \"\" a1b1 with greetings\n",
      "```\n",
      "The student's answer defines a text literal called greetings with the value \"Hello\" and displays it on the dashboard as a label. The variable name used by the student is slightly different from the professor's answer, but it still corresponds to the task. The student also correctly shows the label with the variable greetings. Therefore, the student's answer is OK.  \n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# i propose 2 personalities for the judge\n",
    "# 1st sticks to prior knowledge (eg from python and SQL), 2nd sticks more to professor's answer\n",
    "judge_personality_knowledgeAuthority=\"Your goal is to judge whether the STUDENT ANSWER is OK or NOT_OK, as an answer to the QUESTION.\\\n",
    "In order to judge the STUDENT ANSWER, you are given the PROFESSOR ANSWER which is always OK.\\\n",
    "Difference in details like variable names should be tolerated, as long as it is not specifically demanded in the QUESTION. \\\n",
    "Let's think aloud step by step to help your judgement. \\\n",
    "At the end of your thinking, you must add a new line which contains either OK or NOT_OK and nothing more.\"\n",
    "judge_personality_teacherAuthority=\"Your goal is to judge whether the STUDENT ANSWER is OK or NOT_OK, as an answer to the QUESTION.\\\n",
    "In order to judge the STUDENT ANSWER, you are given the PROFESSOR ANSWER which is always OK.\\\n",
    "Even if the STUDENT ANSWER is not correct by our prior knowledge, we should consider it OK as long as\\\n",
    "it corresponds to the PROFESSOR ANSWER.\\\n",
    "Difference in details like variable names should be tolerated, as long as it is not specifically demanded in the QUESTION. \\\n",
    "Let's think aloud step by step to help your judgement. \\\n",
    "At the end of your thinking, you must add a new line which contains either OK or NOT_OK and nothing more.\"\n",
    "\n",
    "judge_prompt = \"### QUESTION: \"+question+\"\\n### PROFESSOR ANSWER: \"+prof_answer+\"\\n### STUDENT ANSWER: \"+stud_sentence\n",
    "\n",
    "# Generate a response from the chatbot\n",
    "judge_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": judge_personality_teacherAuthority},\n",
    "        {\"role\": \"user\", \"content\": judge_prompt}\n",
    "    ],\n",
    "    max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.2,\n",
    ")\n",
    "print(judge_prompt)\n",
    "# Print the generated response\n",
    "print(judge_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greetings = \"Hello\"\n",
      "show label \"\" a1b1 with greetings\n"
     ]
    }
   ],
   "source": [
    "# extract the 'real' code from the student answer (cut away the '''envision bit at the start and end)\n",
    "def extract_code(stud_sentence):\n",
    "    lines = stud_sentence.strip().split('\\n')\n",
    "    return '\\n'.join(lines[1:-1])\n",
    "print(extract_code(stud_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Failed!\n",
      "Error: 'show %s' expects no 'with'. (Line: 2, Start: 20, Length: 4, Severity: Error)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# send code to online compiler and check if it compiles\n",
    "\n",
    "def check_compilation(script):\n",
    "    url = \"https://try.lokad.com/w/script/trycompile\"\n",
    "    payload = {\n",
    "        \"Script\": script\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send POST request\n",
    "        response = requests.post(url, json=payload)\n",
    "\n",
    "        # Check for successful response\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            if result[\"IsCompOk\"]:\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Compilation Failed!\")\n",
    "                for message in result[\"CompMessages\"]:\n",
    "                    print(f\"Error: {message['Text']} (Line: {message['Line']}, Start: {message['Start']}, Length: {message['Length']}, Severity: {message['Severity']})\")\n",
    "                    return False\n",
    "        else:\n",
    "            print(\"Error: Unable to reach the compilation service.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "check_compilation(extract_code(stud_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each question, try 3 generation-compilations.\n",
    "# if compiles, further check with judge.\n",
    "def pipeline_verify(challenge,coder_personality,judge_personality=judge_personality_teacherAuthority):\n",
    "    question,prof_answer=decompose_challenge(challenge)\n",
    "    n_tries=3\n",
    "    for compile_try in range(n_tries):\n",
    "        coder_prompt=question\n",
    "        coder_response = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": coder_personality},\n",
    "                {\"role\": \"user\", \"content\": coder_prompt}\n",
    "            ],\n",
    "            max_tokens=1000,  # Adjust the number of tokens based on your needs\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        stud_sentence=coder_response.choices[0].message.content\n",
    "        if(check_compilation(extract_code(stud_sentence))):\n",
    "            print('compile ok')\n",
    "            break\n",
    "        elif (compile_try==n_tries-1):\n",
    "            print( \"too many failures !\")\n",
    "            print(extract_code(stud_sentence))\n",
    "            return stud_sentence,\"too many failures !\",False\n",
    "\n",
    "    judge_prompt = \"### QUESTION: \"+question+\"\\n### PROFESSOR ANSWER: \"+prof_answer+\"\\n### STUDENT ANSWER: \"+stud_sentence\n",
    "    judge_response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": judge_personality},\n",
    "            {\"role\": \"user\", \"content\": judge_prompt}\n",
    "        ],\n",
    "        max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    judge_sentence=judge_response.choices[0].message.content\n",
    "    judge_decision=judge_sentence.split(\"\\n\")[-1]\n",
    "    print ('judge_decision:',judge_decision)\n",
    "    return stud_sentence,judge_sentence,(judge_decision=='OK')\n",
    "# a all-in-one function to score a model on a list of challenges\n",
    "def pipeline_score_allchallenge(challenges,coder_personality):\n",
    "    score=0\n",
    "    for challenge in challenges:\n",
    "        _,_,judge_decision=pipeline_verify(challenge,coder_personality)\n",
    "        if (judge_decision): score+=1\n",
    "    print('correct:'+str(score)+' out of '+str(len(challenges))+', '+str(score/len(challenges)*100)+'%')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Failed!\n",
      "Error: 'show %s' expects no 'with'. (Line: 2, Start: 20, Length: 4, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: 'show %s' expects no 'with'. (Line: 5, Start: 20, Length: 4, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: 'show %s' expects no 'with'. (Line: 5, Start: 20, Length: 4, Severity: Error)\n",
      "too many failures !\n",
      "// Define a text literal called greetings with value \"Hello\"\n",
      "greetings = \"Hello\"\n",
      "\n",
      "// Display greetings on the dashboard as a label\n",
      "show label \"\" a1b2 with greetings\n",
      "compile ok\n",
      "judge_decision: OK\n",
      "compile ok\n",
      "judge_decision: OK\n",
      "compile ok\n",
      "judge_decision: OK\n",
      "Compilation Failed!\n",
      "Error: Found identifier but expected 'upload', 'table', tile-type or 'chart'. (Line: 4, Start: 5, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found identifier but expected 'upload', 'table', tile-type or 'chart'. (Line: 4, Start: 5, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found identifier but expected 'upload', 'table', tile-type or 'chart'. (Line: 4, Start: 5, Length: 1, Severity: Error)\n",
      "too many failures !\n",
      "a = 13\n",
      "b = 7\n",
      "y = \"y = \\{a} * x + \\{b}\"\n",
      "show text \"\" a1b1 with y\n",
      "compile ok\n",
      "judge_decision: OK\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "too many failures !\n",
      "table Students = with\n",
      "  [| as Name, as Teacher, as Score |]\n",
      "  [| \"Alice\", \"John Doe\", 85 |]\n",
      "  [| \"Bob\", \"Jane Smith\", 70 |]\n",
      "  [| \"Charlie\", \"John Doe\", 90 |]\n",
      "  [| \"David\", \"John Doe\", 78 |]\n",
      "  [| \"Eve\", \"Jane Smith\", 82 |]\n",
      "\n",
      "Students.Successful = Students.Score > 79\n",
      "\n",
      "show table \"Successful Students of John Doe\" a1c5 with\n",
      "  Students[Teacher == \"John Doe\" and Successful]\n",
      "  mean(Students.Score[Teacher == \"John Doe\" and Successful]) as \"Mean Score\"\n",
      "  max(Students.Score[Teacher == \"John Doe\" and Successful]) as \"Best Score\"\n",
      "  argmax(Students.Score[Teacher == \"John Doe\" and Successful]) as \"Best Student\"\n",
      "compile ok\n",
      "judge_decision: OK\n",
      "correct:5 out of 8, 62.5%\n"
     ]
    }
   ],
   "source": [
    "# test the pipeline. typically fails on challenges 0,4,7 \n",
    "# (these questions include grammar rules not covered in the documentation)\n",
    "\n",
    "# do not use 005(which is not a question of code generation, does not fit in the pipeline format.)\n",
    "\n",
    "indexes=[\"000\",\"001\",\"002\",\"003\",\"004\",\"006\",\"007\",\"008\"]\n",
    "challenges=[readfile(\"mychallenges/c\"+index+\".md\") for index in indexes]\n",
    "pipeline_score_allchallenge(challenges,coder_personality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcher-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
